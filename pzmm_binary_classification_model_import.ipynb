{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Copyright Â© 2023, SAS Institute Inc., Cary, NC, USA.  All Rights Reserved.\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# HMEQ Dataset : Build and Import Trained Binary Classification Models into SAS Model Manager\n",
    "\n",
    "This notebook provides an example of how to build and train a simple Python model and then import the model into SAS Model Manager (on either SAS Viya 3.5 or SAS Viya 4) using the HMEQ data set. Lines of code that must be modified by the user, such as directory paths or the host server are noted with the comment \"_Changes required by user._\".\n",
    "\n",
    "_**Note:** If you download only this notebook and not the rest of the repository, you must also download the hmeq.csv file from the data folder in the examples directory. These files are used when executing this notebook example._\n",
    "\n",
    "Here are the steps shown in this notebook:\n",
    "\n",
    "1. Import, review, and preprocess data for model training.\n",
    "2. Build, train, and assess a scikit-learn decision tree, random forest, and gradient boosting model.\n",
    "3. Serialize the models into separate pickle files.\n",
    "4. Write the metadata JSON files needed for importing into SAS Model Manager as well as optional files for fit statistics and ROC/Lift charts.\n",
    "4. Write a score code Python file for model scoring.\n",
    "5. Zip the pickle, JSON, and score code files into an archive file.\n",
    "6. Import the ZIP archive file to SAS Model Manager via the Session object and relevant function call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Python Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Third Party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Application Specific\n",
    "import sasctl.pzmm as pzmm\n",
    "from sasctl import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Global Package Options\n",
    "pd.options.mode.chained_assignment = None  # default=\"warn\"\n",
    "plt.rc(\"font\", size=14)\n",
    "# Ignore warnings from pandas about SWAT using a feature that will be depreciated soon\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Import and Review Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hmeq_data = pd.read_csv(\"data/hmeq.csv\", sep= \",\")\n",
    "hmeq_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hmeq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hmeq_data.hist(figsize=(15,15), layout=(4, 4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hmeq_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictor_columns = [\"LOAN\", \"MORTDUE\", \"VALUE\", \"YOJ\", \"DEROG\", \"DELINQ\", \"CLAGE\", \"NINQ\", \"CLNO\", \"DEBTINC\"]\n",
    "\n",
    "target_column = \"BAD\"\n",
    "x = hmeq_data[predictor_columns]\n",
    "y = hmeq_data[target_column]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# For missing values, impute the data set's mean value\n",
    "x_test.fillna(x_test.mean(), inplace=True)\n",
    "x_train.fillna(x_train.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Create, Train, and Assess Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=7, min_samples_split=2, min_samples_leaf=2, max_leaf_nodes=500)\n",
    "dtc = dtc.fit(x_train, y_train)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=120, max_depth=9, max_leaf_nodes=850, min_samples_split=5, min_samples_leaf=4)\n",
    "rfc = rfc.fit(x_train, y_train)\n",
    "\n",
    "gbc = GradientBoostingClassifier(learning_rate=0.1, n_estimators=600, max_depth=4, min_samples_leaf=1, min_samples_split=2, max_leaf_nodes=500)\n",
    "gbc = gbc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Calculate the importance of a predictor \n",
    "def sort_feature_importance(model, data):\n",
    "    features = {}\n",
    "    for importance, name in sorted(zip(model.feature_importances_, data.columns), reverse=True):\n",
    "        features[name] = str(np.round(importance*100, 2)) + \"%\"\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "importances = pd.DataFrame.from_dict(sort_feature_importance(dtc, x_train), orient=\"index\").rename(columns={0: \"DecisionTree\"})\n",
    "importances[\"RandomForest\"] = pd.DataFrame.from_dict(sort_feature_importance(rfc, x_train), orient=\"index\")\n",
    "importances[\"GradientBoosting\"] = pd.DataFrame.from_dict(sort_feature_importance(gbc, x_train), orient=\"index\")\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_dtc_predict = dtc.predict(x_test)\n",
    "y_dtc_proba = dtc.predict_proba(x_test)\n",
    "print(confusion_matrix(y_test, y_dtc_predict))\n",
    "print(classification_report(y_test, y_dtc_predict))\n",
    "print(\"Decision Tree Model Accuracy = \" + str(np.round(dtc.score(x_test, y_test)*100,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_rfc_predict = rfc.predict(x_test)\n",
    "y_rfc_proba = rfc.predict_proba(x_test)\n",
    "print(confusion_matrix(y_test, y_rfc_predict))\n",
    "print(classification_report(y_test, y_rfc_predict))\n",
    "print(\"Random Forest Model Accuracy = \" + str(np.round(rfc.score(x_test, y_test)*100,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gbc_predict = gbc.predict(x_test)\n",
    "y_gbc_proba = gbc.predict_proba(x_test)\n",
    "print(confusion_matrix(y_test, y_gbc_predict))\n",
    "print(classification_report(y_test, y_gbc_predict))\n",
    "print(\"Gradient Boosting Model Accuracy = \" + str(np.round(gbc.score(x_test, y_test)*100,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Register Model in SAS Model Manager with pzmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Model names within SAS Model Manager\n",
    "model_prefix = [\"DecisionTreeClassifier\", \"RandomForest\", \"GradientBoosting\"]\n",
    "# Directory location for the model files\n",
    "zip_folder = [Path.cwd() / \"data/hmeqModels/DecisionTreeClassifier/\",\n",
    "             Path.cwd() / \"data/hmeqModels/RandomForest/\",\n",
    "             Path.cwd() / \"data/hmeqModels/GradientBoosting\"] # Changes required by user\n",
    "model = [dtc, rfc, gbc]\n",
    "# Output variables expected in SAS Model Manager. If a classification value is expected to be output, it should be the first metric.\n",
    "score_metrics = [\"EM_CLASSIFICATION\", \"EM_EVENTPROBABILITY\"]\n",
    "\n",
    "# Serialize the models to a pickle format\n",
    "for (mod, prefix, path) in zip(model, model_prefix, zip_folder):\n",
    "    pzmm.PickleModel.pickle_trained_model(\n",
    "        model_prefix=prefix,\n",
    "        trained_model=mod,\n",
    "        pickle_path=path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def write_json_files(data, predict, target, path, prefix):    \n",
    "    # Write input variable mapping to a json file\n",
    "    pzmm.JSONFiles.write_var_json(input_data=data[predict], is_input=True, json_path=path)\n",
    "    \n",
    "    # Set output variables and assign an event threshold, then write output variable mapping\n",
    "    output_var = pd.DataFrame(columns=score_metrics, data=[[\"A\", 0.5]]) # data argument includes example expected types for outputs\n",
    "    pzmm.JSONFiles.write_var_json(output_var, is_input=False, json_path=path)\n",
    "    \n",
    "    # Write model properties to a json file\n",
    "    pzmm.JSONFiles.write_model_properties_json(\n",
    "        model_name=prefix, \n",
    "        target_variable=target, # Target variable to make predictions about (BAD in this case)\n",
    "        target_values=[\"1\", \"0\"], # Possible values for the target variable (1 or 0 for binary classification of BAD)\n",
    "        json_path=path, \n",
    "        model_desc=f\"Description for the {prefix} model.\",\n",
    "        model_algorithm=\"\",\n",
    "        modeler=\"sasdemo\",\n",
    "    )\n",
    "    \n",
    "    # Write model metadata to a json file so that SAS Model Manager can properly identify all model files\n",
    "    pzmm.JSONFiles.write_file_metadata_json(model_prefix=prefix, json_path=path)\n",
    "\n",
    "for (prefix, path) in zip(model_prefix, zip_folder):\n",
    "    write_json_files(hmeq_data, predictor_columns, target_column, path, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "def write_model_stats(x_train, y_train, test_predict, test_proba, y_test, model, path, prefix):\n",
    "    # Calculate train predictions\n",
    "    train_predict = model.predict(x_train)\n",
    "    train_proba = model.predict_proba(x_train)\n",
    "    \n",
    "    # Assign data to lists of actual and predicted values\n",
    "    train_data = pd.concat([y_train.reset_index(drop=True), pd.Series(train_predict), pd.Series(data=train_proba[:,1])], axis=1)\n",
    "    test_data = pd.concat([y_test.reset_index(drop=True), pd.Series(test_predict), pd.Series(data=test_proba[:,1])], axis=1)\n",
    "    \n",
    "    # Calculate the model statistics, ROC chart, and Lift chart; then write to json files\n",
    "    pzmm.JSONFiles.calculate_model_statistics(\n",
    "        target_value=1, \n",
    "        prob_value=0.5, \n",
    "        train_data=train_data, \n",
    "        test_data=test_data, \n",
    "        json_path=path\n",
    "    )\n",
    "\n",
    "    full_training_data = pd.concat([y_train.reset_index(drop=True), x_train.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    pzmm.JSONFiles.generate_model_card(\n",
    "        model_prefix=prefix,\n",
    "        model_files = path,\n",
    "        algorithm = str(type(model).__name__),\n",
    "        train_data = full_training_data,\n",
    "        train_predictions=train_predict,\n",
    "        target_type='classification',\n",
    "        target_value=1,\n",
    "        interval_vars=predictor_columns,\n",
    "        selection_statistic='_RASE_',\n",
    "    )\n",
    "        \n",
    "username = getpass.getpass()\n",
    "password = getpass.getpass()\n",
    "host = \"demo.sas.com\"# Changes required by user\n",
    "sess = Session(host, username, password, protocol=\"http\") # For TLS-enabled servers, change protocol value to \"https\"\n",
    "conn = sess.as_swat() # Connect to SWAT through the sasctl authenticated connection\n",
    "\n",
    "test_predict = [y_dtc_predict, y_rfc_predict, y_gbc_predict]\n",
    "test_proba = [y_dtc_proba, y_rfc_proba, y_gbc_proba]\n",
    "for (mod, pred, proba, path, prefix) in zip(model, test_predict, test_proba, zip_folder, model_prefix):\n",
    "    write_model_stats(x_train, y_train, pred, proba, y_test, mod, path, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for (prefix, path) in zip(model_prefix, zip_folder):\n",
    "    pzmm.ImportModel.import_model(\n",
    "        model_files=path, # Where are the model files?\n",
    "        model_prefix=prefix, # What is the model name?\n",
    "        project=\"HMEQModels\", # What is the project name?\n",
    "        input_data=x, # What does example input data look like?\n",
    "        predict_method=[dtc.predict_proba, [int, int]], # What is the predict method and what does it return?\n",
    "        score_metrics=score_metrics, # What are the output variables?\n",
    "        overwrite_model=True, # Overwrite the model if it already exists?\n",
    "        target_values=[\"0\", \"1\"], # What are the expected values of the target variable?\n",
    "        target_index=1, # What is the index of the target value in target_values?\n",
    "        model_file_name=prefix + \".pickle\", # How was the model file serialized?\n",
    "        missing_values=True # Does the data include missing values?\n",
    "    )\n",
    "    # Reinitialize the score_code variable when writing more than one model's score code\n",
    "    pzmm.ScoreCode.score_code = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Score Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "\n",
    "from sasctl._services.score_definitions import ScoreDefinitions as sd # Importing ScoreDefinitions service\n",
    "from sasctl._services.score_execution import ScoreExecution as se # Importing ScoreExecution service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the score definition for this model using the model UUID generated two steps before\n",
    "score_definition = sd.create_score_definition(\n",
    "    \"example_score_def_name\", # Name of the score_definition, which can be any string\n",
    "    \"model_id\",  # Use Model UUID generated two steps before\n",
    "    \"table_name\", # Table name for input data, which must exist in host server or it will throw an HTTP error and prompt you to upload a data file\n",
    "    # True,  # Uncomment 'True' if your Viya version is compatible with CAS Gateway\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing the score definition\n",
    "score_execution = se.create_score_execution(\n",
    "    score_definition.get(\"id\") # Score definition id created in the previous cell\n",
    ")\n",
    "\n",
    "# Prints score_execution_id\n",
    "print(score_execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view our scored model information within Model Manager under Projects -> Choose your model -> Scoring. \n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
